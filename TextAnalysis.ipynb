{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B5gQyn-nF0hiDzwUmBt_h4AtwHXASTnr",
      "authorship_tag": "ABX9TyNqQpMXNDfeifR2+i6wsK0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markeldon32/hello-world/blob/master/TextAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvx0hZpkpfly",
        "colab_type": "text"
      },
      "source": [
        "###To learn evaluating Text with sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5SRDI2Io96N",
        "colab_type": "code",
        "outputId": "4bd6e4c3-f0c8-4a17-bed3-ccec2e4d3fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# read json into a data frame\n",
        "df_idf = pd.read_json('https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-data-idf.json', lines=True)\n",
        "\n",
        "#print Schema\n",
        "print('Schema:\\n\\n', df_idf.dtypes)\n",
        "print('Number of questions, columns=', df_idf.shape)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Schema:\n",
            "\n",
            " id                            int64\n",
            "title                        object\n",
            "body                         object\n",
            "answer_count                  int64\n",
            "comment_count                 int64\n",
            "creation_date                object\n",
            "last_activity_date           object\n",
            "last_editor_display_name     object\n",
            "owner_display_name           object\n",
            "owner_user_id               float64\n",
            "post_type_id                  int64\n",
            "score                         int64\n",
            "tags                         object\n",
            "view_count                    int64\n",
            "accepted_answer_id          float64\n",
            "favorite_count              float64\n",
            "last_edit_date               object\n",
            "last_editor_user_id         float64\n",
            "community_owned_date         object\n",
            "dtype: object\n",
            "Number of questions, columns= (20000, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9y2aWdZswct",
        "colab_type": "code",
        "outputId": "1f0db65b-40a9-4a3d-f155-6897514e7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "\n",
        "  #lowercase\n",
        "  text=text.lower()\n",
        "  #remove tags\n",
        "  text=re.sub('&lt;/?.*?&gt;','&lt;&gt;',text)\n",
        "  #remove special characters and digits\n",
        "  text=re.sub('(\\\\d|\\\\W)+',' ',text)\n",
        "\n",
        "  return text\n",
        "\n",
        "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
        "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#show the first 'text'\n",
        "df_idf['text'][2]\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gradle command line p i m trying to run a shell script with gradle i currently have something like this p pre code def test project tasks create test exec commandline bash c bash c my file dir script sh code pre p the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g p pre code commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath code pre p im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces p '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oRSUt4oz07W",
        "colab_type": "code",
        "outputId": "962b1bbf-1bd5-4232-cda3-4fd4111f0290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "\n",
        "def get_stop_words(stop_file_path):\n",
        "  \"\"\"load stop words \"\"\"\n",
        "\n",
        "  with open(stop_file_path, 'r', encoding='utf-8') as f:\n",
        "    stopwords= f.readlines()\n",
        "    stop_set=set(m.strip() for m in stopwords)\n",
        "    return frozenset(stop_set)\n",
        "\n",
        "#load a set of stopwords\n",
        "stopwords=get_stop_words('/content/drive/My Drive/Colab Notebooks/stopwords.txt')\n",
        "\n",
        "#get the text column\n",
        "docs=df_idf['text'].tolist()\n",
        "\n",
        "#create a vocabulary of word\n",
        "#ignore words that appear in 85% of the documents\n",
        "#eliminate stopwords\n",
        "cv= CountVectorizer(max_df=0.85, stop_words=stopwords)\n",
        "word_count_vector=cv.fit_transform(docs)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWMDvBTAkE0u",
        "colab_type": "code",
        "outputId": "c99506f8-b48b-4b48-f64b-09900877c931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
        "word_count_vector=cv.fit_transform(docs)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS-2hkOonZeK",
        "colab_type": "code",
        "outputId": "4d9b0227-0a2e-4600-cdab-8233d6ca2716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "list(cv.vocabulary_.keys())[:20]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['serializing',\n",
              " 'private',\n",
              " 'struct',\n",
              " 'done',\n",
              " 'public',\n",
              " 'class',\n",
              " 'contains',\n",
              " 'properties',\n",
              " 'mostly',\n",
              " 'string',\n",
              " 'want',\n",
              " 'serialize',\n",
              " 'attempt',\n",
              " 'stream',\n",
              " 'disk',\n",
              " 'using',\n",
              " 'xmlserializer',\n",
              " 'get',\n",
              " 'error',\n",
              " 'saying']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJVzgJ-BoQTd",
        "colab_type": "code",
        "outputId": "cf904c85-819e-4e2a-a121-96a255b4b98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wft4FFELjyu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read test docs into dataframe and concatenate title and body\n",
        "df_test=pd.read_json('https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-test.json',lines=True)\n",
        "df_test['text'] = df_test['title'] + df_test['body']\n",
        "df_test['text'] = df_test['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#test docs into a list\n",
        "docs_test=df_test['text'].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bX-61nW6F08",
        "colab_type": "code",
        "outputId": "924cda0a-3c29-4eb9-9f16-bef410089446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "# you only need to do this once, as this is a mapping index to\n",
        "feature_names = cv.get_feature_names()\n",
        "\n",
        "# get the document which we want to extract the keywords\n",
        "doc= docs_test[0]\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "# sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "#extract only the top n; n = 10\n",
        "keywords=extract-topn_from_vector(feature_names, sorted_items,10)\n",
        "\n",
        "#print the results\n",
        "print('\\n=====Doc=====')\n",
        "print(doc)\n",
        "print('\\n===Keywords===')\n",
        "for k in keywords:\n",
        "  print(k,keywords[k])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-1deb68c997b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# sort the tf-idf vectors by descending order of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msorted_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_coo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#extract only the top n; n = 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sort_coo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOMEVa-hsbOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}