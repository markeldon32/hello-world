{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B5gQyn-nF0hiDzwUmBt_h4AtwHXASTnr",
      "authorship_tag": "ABX9TyPEtpWQQGLhtQnZb8Twe0Ek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markeldon32/hello-world/blob/readme-edits/TextAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvx0hZpkpfly",
        "colab_type": "text"
      },
      "source": [
        "###To learn evaluating Text with sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5SRDI2Io96N",
        "colab_type": "code",
        "outputId": "834118c7-f5e1-4453-ca86-9e4b5b5b21fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# read json into a data frame\n",
        "df_idf = pd.read_json('https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-data-idf.json', lines=True)\n",
        "\n",
        "#print Schema\n",
        "print('Schema:\\n\\n', df_idf.dtypes)\n",
        "print('Number of questions, columns=', df_idf.shape)\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Schema:\n",
            "\n",
            " id                            int64\n",
            "title                        object\n",
            "body                         object\n",
            "answer_count                  int64\n",
            "comment_count                 int64\n",
            "creation_date                object\n",
            "last_activity_date           object\n",
            "last_editor_display_name     object\n",
            "owner_display_name           object\n",
            "owner_user_id               float64\n",
            "post_type_id                  int64\n",
            "score                         int64\n",
            "tags                         object\n",
            "view_count                    int64\n",
            "accepted_answer_id          float64\n",
            "favorite_count              float64\n",
            "last_edit_date               object\n",
            "last_editor_user_id         float64\n",
            "community_owned_date         object\n",
            "dtype: object\n",
            "Number of questions, columns= (20000, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9y2aWdZswct",
        "colab_type": "code",
        "outputId": "66d86bc4-0eb6-4339-de37-a72acccdf661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "\n",
        "  #lowercase\n",
        "  text=text.lower()\n",
        "  #remove tags\n",
        "  text=re.sub('&lt;/?.*?&gt;','&lt;&gt;',text)\n",
        "  #remove special characters and digits\n",
        "  text=re.sub('(\\\\d|\\\\W)+',' ',text)\n",
        "\n",
        "  return text\n",
        "\n",
        "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
        "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#show the first 'text'\n",
        "df_idf['text'][2]\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gradle command line p i m trying to run a shell script with gradle i currently have something like this p pre code def test project tasks create test exec commandline bash c bash c my file dir script sh code pre p the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g p pre code commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath code pre p im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces p '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oRSUt4oz07W",
        "colab_type": "code",
        "outputId": "cfad74c2-010e-4d7a-ad9c-8522d924070b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "\n",
        "def get_stop_words(stop_file_path):\n",
        "  \"\"\"load stop words \"\"\"\n",
        "\n",
        "  with open(stop_file_path, 'r', encoding='utf-8') as f:\n",
        "    stopwords= f.readlines()\n",
        "    stop_set=set(m.strip() for m in stopwords)\n",
        "    return frozenset(stop_set)\n",
        "\n",
        "#load a set of stopwords\n",
        "stopwords=get_stop_words('/content/drive/My Drive/Colab Notebooks/stopwords.txt')\n",
        "\n",
        "#get the text column\n",
        "docs=df_idf['text'].tolist()\n",
        "\n",
        "#create a vocabulary of word\n",
        "#ignore words that appear in 85% of the documents\n",
        "#eliminate stopwords\n",
        "cv= CountVectorizer(max_df=0.85, stop_words=stopwords)\n",
        "word_count_vector=cv.fit_transform(docs)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0aUCzvfCz-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a0464b3-2b9a-495f-d9bb-552c4a2ed5d4"
      },
      "source": [
        "word_count_vector.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWMDvBTAkE0u",
        "colab_type": "code",
        "outputId": "a4bca23e-6532-4446-bf4e-602e714a6ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
        "word_count_vector=cv.fit_transform(docs)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS-2hkOonZeK",
        "colab_type": "code",
        "outputId": "528dce8c-70da-4193-ab36-100f6f7f040d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "list(cv.vocabulary_.keys())[:20]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['serializing',\n",
              " 'private',\n",
              " 'struct',\n",
              " 'done',\n",
              " 'public',\n",
              " 'class',\n",
              " 'contains',\n",
              " 'properties',\n",
              " 'mostly',\n",
              " 'string',\n",
              " 'want',\n",
              " 'serialize',\n",
              " 'attempt',\n",
              " 'stream',\n",
              " 'disk',\n",
              " 'using',\n",
              " 'xmlserializer',\n",
              " 'get',\n",
              " 'error',\n",
              " 'saying']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wrzE_xcD7Kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "57cdac26-1bf4-4576-8263-a5789a9d3886"
      },
      "source": [
        "list(cv.get_feature_names())[2000:2015]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['damage',\n",
              " 'dan',\n",
              " 'dao',\n",
              " 'dapper',\n",
              " 'dark',\n",
              " 'dart',\n",
              " 'darwin',\n",
              " 'dash',\n",
              " 'dashboard',\n",
              " 'dat',\n",
              " 'data',\n",
              " 'data_',\n",
              " 'data_dir',\n",
              " 'dataaccess',\n",
              " 'database']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJVzgJ-BoQTd",
        "colab_type": "code",
        "outputId": "1f2469de-ef98-4add-e774-b7ffda359d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OrnfufjEYvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b365ce55-2c1f-4872-a834-3677d6a0fb85"
      },
      "source": [
        "tfidf_transformer.idf_"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.53624172,  9.80492526,  9.51724319, ...,  8.82409601,\n",
              "       10.21039037,  9.51724319])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wft4FFELjyu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read test docs into dataframe and concatenate title and body\n",
        "df_test=pd.read_json('https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-test.json',lines=True)\n",
        "df_test['text'] = df_test['title'] + df_test['body']\n",
        "df_test['text'] = df_test['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "# get test docs into a list\n",
        "docs_test=df_test['text'].tolist()\n",
        "docs_title=df_test['title'].tolist()\n",
        "docs_body=df_test['body'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m8ij618FVdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bX-61nW6F08",
        "colab_type": "code",
        "outputId": "e1acae89-b15f-47d5-9a45-5d73eed42cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "# you only need to do this once, as this is a mapping index to\n",
        "feature_names=cv.get_feature_names()\n",
        "\n",
        "# get the document that we want to extract keywords from\n",
        "doc=docs_test[0]\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "#sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "#extract only the top n; n here is 10\n",
        "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "\n",
        "# now print the results\n",
        "print(\"\\n=====Title=====\")\n",
        "print(docs_title[0])\n",
        "print(\"\\n=====Body=====\")\n",
        "print(docs_body[0])\n",
        "print(\"\\n===Keywords===\")\n",
        "for k in keywords:\n",
        "    print(k,keywords[k])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Title=====\n",
            "Integrate War-Plugin for m2eclipse into Eclipse Project\n",
            "\n",
            "=====Body=====\n",
            "<p>I set up a small web project with JSF and Maven. Now I want to deploy on a Tomcat server. Is there a possibility to automate that like a button in Eclipse that automatically deploys the project to Tomcat?</p>\n",
            "\n",
            "<p>I read about a the <a href=\"http://maven.apache.org/plugins/maven-war-plugin/\" rel=\"nofollow noreferrer\">Maven War Plugin</a> but I couldn't find a tutorial how to integrate that into my process (eclipse/m2eclipse).</p>\n",
            "\n",
            "<p>Can you link me to help or try to explain it. Thanks.</p>\n",
            "\n",
            "===Keywords===\n",
            "eclipse 0.491\n",
            "maven 0.453\n",
            "war 0.394\n",
            "plugin 0.266\n",
            "integrate 0.233\n",
            "tomcat 0.224\n",
            "project 0.198\n",
            "automate 0.131\n",
            "jsf 0.125\n",
            "possibility 0.121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOMEVa-hsbOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}